\section{Mutation-Testing-Based Fuzzing}



\subsection{Mutation-Based Fuzzing}

One use of the term ``mutation'' appears in the context of the ``no-fuss'' \emph{mutation-based} fuzzing discussed above~\cite{ArtFuzz}.  A fuzzer such as AFL operates by executing the program under test (here, the compiler) on inputs (initially those in a corpus of example programs), using instrumentation to determine code coverage for each executed input.  The fuzzer then takes inputs that look interesting (e.g., uniquely cover some compiler code) and adds them to a \emph{queue}.  The basic loop repeatedly takes some input from the queue, \emph{mutates} it by making some essentially random change (e.g., flipping a single bit, or removing a random chunk of bytes), then executes the new, mutated input under instrumentation, and adds the new input to the queue if it satisfies the fuzzer's coverage-based criteria for interesting inputs.  The details of selecting inputs from the queue and determining how to mutate an input vary widely, and improving the effectiveness of this basic approach has been a major topic of recent software testing and security research~\cite{evalfuzz,BoehmeCR21,ArtFuzz}.  However, the basic strategy is simple:

\begin{enumerate}
\item Select an input from the queue.
\item Mutate that input in order to obtain a new input.
\item Execute the new input, and if it is deemed interesting, add it to the queue.
\item Go back to the first step.
\end{enumerate}

Any inputs that crash the compiler in step 3 are reported to the user.  Using such a fuzzer is often extremely easy, involving no more work than 1) building the compiler with special instrumentation\footnote{With AFL this is fairly trivial, by using a drop-in compiler replacement, for C, C++, Rust; there are AFL variants for Go, Python, and other languages, as well.  AFL can also use QEMU to fuzz arbitrary binaries.  However, for compilers, it is usually best if possible to rebuild the compiler, since QEMU-based execution is much slower, and fuzz throughput is important.} and 2) finding a set of initial programs to use as a corpus.  


Our work focuses on improving step 2 of this process, in a way that is agnostic to how the details of the other aspects of fuzzing are implemented.  In particular, the problem with most approaches to mutation in the literature, for compiler fuzzing, is that changes such as byte-level-transformations almost always take compiling programs that exercise interesting compiler behavior, and transform them into programs that don't make it past early stages of parsing.  Alternative approaches to what are called ``havoc''-style mutations tend to involve solving constraints~\cite{Eclipser} or following taint~\cite{Angora}, which in the case of compilers tends to be ineffective, since the relationships to too complex to solve/follow.  A second common approach, providing a \emph{dictionary} of meaningful byte sequences in a language, is both burdensome on compiler developers (though less so than providing a full grammar), and limited in effectiveness: a dictionary cannot, for example, help the fuzzer delete meaningful sub-units of code, such as statements or blocks.

We propose a novel way to produce a much larger number of useful, interesting mutations for source code, without paying an analytical price that makes fuzzing practically infeasible for compilers, and without requiring \emph{any} additional effort on the part of compiler developers.

\subsection{Mutation Testing}

A different use of the term ``mutation'' appears in the field of mutation testing.  Mutation testing~\cite{MutationSurvey,budd1979mutation,demillo1978hints} is an approach to evaluating and improving software tests that works by introducing small syntactic changes into a program, under the assumption that if the original program was correct, then a program with slightly different semantics will be incorrect, and should be flagged as such by effective tests.  Mutation testing is now widely used in software testing research, and is used to varying degrees in industry at-scale and for especially critical software development~\cite{mutKernel,mutGoogle,mutFacebook}.

A mutation testing approach is defined by a set of mutation operators.  Such operators vary widely in the literature, though a few, such as deleting a small portion of code (such as a statement) or replacing arithmetic and relational operations (e.g., changing {\tt +} to {\tt -} or {\tt ==} to {\tt <=}), are very widely used.  Most mutation testing tools parse the code to be mutated do not work on code that does not parse.  However, recently there has been a proposal to perform mutation using purely syntactic operations, defined by a set of regular expressions~\cite{regexpMut}.  Rather than taking a program, per se, this approach simply takes ``code-like'' text and produces a set of variants that will include most common mutations.  The essence of this approach to mutation testing, which can be applied to ``any language,'' is essentially a transformation from arbitrary bytes to arbitrary bytes that, \emph{if the original bytes are ``code-like'' will tend to preserve that property}.  The resemblance to the mutations performed by mutation-based fuzzers is the core insight behind our approach.

\subsection{Combining Both Forms of Mutation}

The core of our approach is simply to add a new set of mutations to the repertoire of a mutation-based fuzzer.  These mutations are either traditional mutation operators or inspired by traditional mutation operators, but with changes made to satisfy the needs of fuzzing.  Unlike most changes made by mutation-based fuzzers, these mutations are likely to preserve the property that an input will get through a parser or trigger interesting optimizations.  The tendency to preserve such properties is natural, since the basis of mutation testing is to take an existing program and produce a set of new, similar programs.  If most mutation operators tended to produce uninteresting code that doesn't even compile, mutation testing would not be of much use.  Moreover, because our approach is based on the idea of a ``universal'' mutation tool~\cite{regexpMut}, the mutation operators used are generally language-agnostic, and useful for fuzzing any programming language that syntactically resembles common languages (under which we include not only C-like languages, but even LISP-like languages). Staying within the theme of preserving code structure, we further enable an augmentation of our approach where we decompose existing test programs into constituent fragments that are then used to synthesize and mutate new inputs at runtime.

\subsection{Limitations}

The most important limitation for the mutation-testing-based approach is that if compiler \emph{crashes} are mostly uninteresting, fuzzing of this kind will probably not be very useful.  This applies, of course, to all AFL-style fuzzing, not just our approach.  For example, code that crashes a C or C++ compiler, but that includes extensive undefined behavior may well be ignored by developers.  Csmith~\cite{csmith} devotes a great deal of effort to avoiding generating such code.  On the other hand, many languages more recent than C and C++ attempt to provide a more ``total'' language where, while a program may be considered absurd by a human, fewer (or no) programs are undefined.  For example, smart contract languages such as those studied in this paper generally aim to make all programs that compile well-defined, or at least minimize the problem to more managable cases such as order of evaluation of sub-expressions.  Similarly, Rust code without use of {\tt unsafe} should not crash the compiler, and any such crashes indicate possible bugs in the Rust compiler or type system.  
